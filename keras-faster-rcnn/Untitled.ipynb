{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from PIL import Image\n",
    "np.array(Image.open(VALIDATION_DIR+'0001eeaf4aed83f9.jpg')).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/wcw/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from cfg import *\n",
    "from utils.generator import *\n",
    "from model.rpn import *\n",
    "# from model.head import *\n",
    "\n",
    "from keras import layers, models\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "import keras.backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "gen = OIDGen('split_1_annotation.json', batch_size=1)\n",
    "img_size = gen[0][0][0].shape.as_list()[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16        \n",
    "vgg16 = VGG16(include_top=False, )\n",
    "backbone = models.Model(vgg16.input, vgg16.get_layer('block5_conv3').output)\n",
    "\n",
    "x = backbone(gen[0][0])\n",
    "# initial rpn model\n",
    "rpn = RPN(img_size)(x)\n",
    "\n",
    "proposals, scores = rpn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoiPooling(layers.Layer):\n",
    "    def __init__(self, pool_width=7, pool_height=7, ):\n",
    "        super(RoiPooling, self).__init__()\n",
    "        self.pool_width = pool_width\n",
    "        self.pool_height = pool_height\n",
    "\n",
    "    def call(self, inp):\n",
    "        # x (1, 16, 16, 512)\n",
    "        # rois (N, 4)\n",
    "        x, rois = inp\n",
    "\n",
    "        x_shape = x.shape.as_list()[1:3][::-1]\n",
    "        scale = tf.Variable(x_shape+x_shape, dtype=tf.float32)        \n",
    "        rois /= scale\n",
    "        rois_pool = tf.image.crop_and_resize(x,rois, tf.zeros([tf.shape(rois)[0]], dtype=tf.int32), [self.pool_height, self.pool_width])        \n",
    "#         rois_pool = tf.map_fn(self.helper, rois)\n",
    "\n",
    "        return rois_pool     \n",
    "    \n",
    "    def compute_output_shape(self, inp):\n",
    "        x, rois = inp\n",
    "        return (1,None)+ x[1:]\n",
    "    \n",
    "    def helper(self, inp):\n",
    "        x_shape = x.shape.as_list()[1:3][::-1]\n",
    "        scale = tf.Variable(x_shape+x_shape, dtype=tf.float32)\n",
    "        roi = tf.cast(inp[0] / scale, tf.int32)\n",
    "        roi_pool = tf.image.resize_images(x[0,roi[0]:roi[2], roi[1]:roi[3],:], [self.pool_height,self.pool_width],)\n",
    "        return roi_pool        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoiAlian(layers.Layer):\n",
    "    def __init__(self, pool_height=7, pool_width=7):\n",
    "        super(RoiAlian, self).__init__()\n",
    "        self.pool_height = pool_height\n",
    "        self.pool_width = pool_width\n",
    "\n",
    "    def call(self, inp,):\n",
    "        x, rois = inp\n",
    "        x = tf.pad(x, [[0,0],[1,1],[1,1],[0,0]], mode='SYMMETRIC')\n",
    "        rois += 1\n",
    "\n",
    "        x0,y0,x1,y1 = tf.split(rois, 4, 1)\n",
    "        w = x1 - x0\n",
    "        h = y1 - y0\n",
    "\n",
    "        xx = (x0 + w/2/self.pool_width - .5) / tf.to_float(tf.shape(x)[2])\n",
    "        yy = (y0 + h/2/self.pool_height - .5) / tf.to_float(tf.shape(x)[1])\n",
    "\n",
    "        w /= tf.to_float(tf.shape(x)[2])\n",
    "        h /= tf.to_float(tf.shape(x)[1])\n",
    "        rois =  tf.concat([xx, yy, xx+w, yy+h], axis=1)\n",
    "        roi_pools = tf.image.crop_and_resize(x, rois, tf.zeros([tf.shape(rois)[0]], dtype=tf.int32), \n",
    "                                [self.pool_width, self.pool_height])\n",
    "        roi_pools = layers.AveragePooling2D(strides=2 , padding=\"same\")(roi_pools)\n",
    "        return roi_pools\n",
    "\n",
    "    def compute_output_shape(self, inp):\n",
    "        x, rois = inp\n",
    "        return (None,) + x[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'model_1/block5_conv3/Relu:0' shape=(1, 64, 30, 512) dtype=float32>,\n",
       " <tf.Tensor 'model_2/proposal_layer_1/GatherV2_3:0' shape=(?, 4) dtype=float32>,\n",
       " <tf.Tensor 'model_2/proposal_layer_1/GatherV2_4:0' shape=(?,) dtype=float32>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, proposals, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = RoiAlian()([x,proposals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'roi_alian_9/average_pooling2d_3/AvgPool:0' shape=(?, 4, 4, 512) dtype=float32>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'flatten_1/Reshape:0' shape=(?, ?) dtype=float32>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers.Flatten()(roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'model_1_1/block5_conv3/Relu:0' shape=(?, ?, ?, 512) dtype=float32>,\n",
       " <tf.Tensor 'model_2_1/proposal_layer_1/GatherV2_3:0' shape=(?, 4) dtype=float32>,\n",
       " <tf.Tensor 'model_2_1/proposal_layer_1/GatherV2_4:0' shape=(?,) dtype=float32>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_, x_1, x_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, 512]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_.shape.as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The shape of the input to \"Flatten\" is not fully defined (got (None, None, 512). Make sure to pass a complete \"input_shape\" or \"batch_input_shape\" argument to the first layer in your model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-9a4e1cb83f32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLEVEL_1_LABEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-57-713b01cf1ec2>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#         inp = layers.Input(x_shape[1:])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mx_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         x_ = layers.Dense(4096, activation='relu',\n\u001b[1;32m     14\u001b[0m                     \u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    472\u001b[0m             if all([s is not None\n\u001b[1;32m    473\u001b[0m                     for s in to_list(input_shape)]):\n\u001b[0;32m--> 474\u001b[0;31m                 \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/keras/layers/core.py\u001b[0m in \u001b[0;36mcompute_output_shape\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    498\u001b[0m             raise ValueError('The shape of the input to \"Flatten\" '\n\u001b[1;32m    499\u001b[0m                              \u001b[0;34m'is not fully defined '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m                              \u001b[0;34m'(got '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m                              \u001b[0;34m'Make sure to pass a complete \"input_shape\" '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m                              \u001b[0;34m'or \"batch_input_shape\" argument to the first '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The shape of the input to \"Flatten\" is not fully defined (got (None, None, 512). Make sure to pass a complete \"input_shape\" or \"batch_input_shape\" argument to the first layer in your model."
     ]
    }
   ],
   "source": [
    "inp = vgg16.input\n",
    "\n",
    "x_ = backbone(inp)\n",
    "\n",
    "x_1, x_2 = rpn(x_)\n",
    "x_ = RoiAlian()([x_,x_1])\n",
    "# models.Model(inp, x_)\n",
    "\n",
    "\n",
    "head = Head(len(LEVEL_1_LABEL))\n",
    "\n",
    "bbox, score = head(x_)\n",
    "\n",
    "models.Model(inp, [bbox,score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.engine.training.Model"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rpn.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'flatten_20/Reshape:0' shape=(?, ?) dtype=float32>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers.Flatten()(roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'dense_32/BiasAdd:0' shape=(?, 1772) dtype=float32>,\n",
       " <tf.Tensor 'dense_31/Softmax:0' shape=(?, 443) dtype=float32>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head = Head(len(LEVEL_1_LABEL))\n",
    "head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head:\n",
    "    def __init__(self, n_classes):\n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "\n",
    "    def __call__(self, x):\n",
    "        # x (batch_size=1, rois, pool_width, pool_height, channels)\n",
    "        x_shape = x.shape.as_list()\n",
    "\n",
    "#         inp = layers.Input(x_shape[1:])\n",
    "\n",
    "        x_ = layers.Flatten()(x)\n",
    "        x_ = layers.Dense(4096, activation='relu',\n",
    "                    kernel_regularizer=regularizers.l2(1.0),\n",
    "                    bias_regularizer=regularizers.l2(2.0))(x_)\n",
    "        x_ = layers.Dense(4096, activation='relu',\n",
    "                    kernel_regularizer=regularizers.l2(1.0),\n",
    "                    bias_regularizer=regularizers.l2(2.0))(x_)\n",
    "        \n",
    "        score = layers.Dense(self.n_classes, activation='softmax',\n",
    "                    kernel_initializer=initializers.random_normal(stddev=0.01))(x_)    \n",
    "        bbox = layers.Dense(self.n_classes*4, activation='linear',\n",
    "                    kernel_initializer=initializers.random_normal(stddev=0.01))(x_)\n",
    "#         head_model = models.Model(inp, [bbox, score])\n",
    "#         return head_model\n",
    "        return bbox, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  2.,  3.,  4.],\n",
       "       [ 5.,  6.,  7.,  8.,  9.],\n",
       "       [10., 11., 12., 13., 14.],\n",
       "       [15., 16., 17., 18., 19.],\n",
       "       [20., 21., 22., 23., 24.]], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image[0,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.arange(25).astype('float32').reshape(5, 5)\n",
    "image = image[None,:,:,None]\n",
    "boxes = np.asarray([[0, 0, 4, 4]], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    sess.run(c)\n",
    "    print(c.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__name__': '__main__',\n",
       " '__doc__': 'Automatically created module for IPython interactive environment',\n",
       " '__package__': None,\n",
       " '__loader__': None,\n",
       " '__spec__': None,\n",
       " '__builtin__': <module 'builtins' (built-in)>,\n",
       " '__builtins__': <module 'builtins' (built-in)>,\n",
       " '_ih': ['',\n",
       "  'import tensorflow as tf\\ntf.',\n",
       "  'import tensorflow as tf\\ntf.keras',\n",
       "  'global()',\n",
       "  'global',\n",
       "  'globals()',\n",
       "  'for a in globals():\\n    print(a)',\n",
       "  'globals(0)',\n",
       "  'globals()'],\n",
       " '_oh': {2: <module 'tensorflow._api.v1.keras' from '/home/wcw/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/_api/v1/keras/__init__.py'>,\n",
       "  5: {...}},\n",
       " '_dh': ['/home/wcw/Documents/py-faster-rcnn/keras-faster-rcnn'],\n",
       " 'In': ['',\n",
       "  'import tensorflow as tf\\ntf.',\n",
       "  'import tensorflow as tf\\ntf.keras',\n",
       "  'global()',\n",
       "  'global',\n",
       "  'globals()',\n",
       "  'for a in globals():\\n    print(a)',\n",
       "  'globals(0)',\n",
       "  'globals()'],\n",
       " 'Out': {2: <module 'tensorflow._api.v1.keras' from '/home/wcw/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/_api/v1/keras/__init__.py'>,\n",
       "  5: {...}},\n",
       " 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f432c38e0b8>>,\n",
       " 'exit': <IPython.core.autocall.ZMQExitAutocall at 0x7f432c3b3470>,\n",
       " 'quit': <IPython.core.autocall.ZMQExitAutocall at 0x7f432c3b3470>,\n",
       " '_': {...},\n",
       " '__': <module 'tensorflow._api.v1.keras' from '/home/wcw/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/_api/v1/keras/__init__.py'>,\n",
       " '___': '',\n",
       " '_i': 'globals(0)',\n",
       " '_ii': 'for a in globals():\\n    print(a)',\n",
       " '_iii': 'globals()',\n",
       " '_i1': 'import tensorflow as tf\\ntf.',\n",
       " '_i2': 'import tensorflow as tf\\ntf.keras',\n",
       " 'tf': <module 'tensorflow' from '/home/wcw/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/__init__.py'>,\n",
       " '_2': <module 'tensorflow._api.v1.keras' from '/home/wcw/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/_api/v1/keras/__init__.py'>,\n",
       " '_i3': 'global()',\n",
       " '_i4': 'global',\n",
       " '_i5': 'globals()',\n",
       " '_5': {...},\n",
       " '_i6': 'for a in globals():\\n    print(a)',\n",
       " 'a': '__name__',\n",
       " '_i7': 'globals(0)',\n",
       " '_i8': 'globals()'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow._api.v1.keras' from '/home/wcw/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/_api/v1/keras/__init__.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.Assert()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
